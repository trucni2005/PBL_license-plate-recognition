{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import các thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dangt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dùng model là yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\dangt/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-3-20 Python-3.10.0 torch-1.13.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='weights/best.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hàm xuất ra ma trận nhị phân đặc trưng cho kí tự"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xuất ra ma trận nhị phân ( đen = 0, trắng = 255)\n",
    "def feature(folder_path, file):\n",
    "    binaries = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.png'):\n",
    "            # Đọc tệp tin ảnh\n",
    "            img = cv2.imread(os.path.join(folder_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Đổi ảnh sang ma trận nhị phân\n",
    "            ret, binary = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            # Thêm ma trận nhị phân vào mảng\n",
    "            binaries.append(binary)\n",
    "        \n",
    "\n",
    "    # Khởi tạo mảng pixel trắng đen có kích thước giống với các ma trận trong binaries với các phần tử được khởi tạo là 0\n",
    "    black_pixels = np.zeros_like(binaries[0])\n",
    "    white_pixels = np.zeros_like(binaries[0])\n",
    "    \n",
    "    # Tính toán số lượng pixel màu đen và màu trắng cho từng pixel trong các ma trận\n",
    "    for binary in binaries:\n",
    "        black_pixels += binary == 0\n",
    "        white_pixels += binary == 255\n",
    "\n",
    "    # So sánh số lượng pixel màu đen và màu trắng để quyết định màu sắc cuối cùng của pixel trong ma trận đặc trưng\n",
    "    feature = np.zeros_like(binaries[0], dtype=np.uint8)\n",
    "    for i in range(feature.shape[0]):\n",
    "        for j in range(feature.shape[1]):\n",
    "            if black_pixels[i][j] > white_pixels[i][j]:\n",
    "                feature[i][j] = 0\n",
    "            else:\n",
    "                feature[i][j] = 255\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xuất ra ma trận đặc trưng cho tất cả các kí tự"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "folder_path = \"char/\"\n",
    "files = os.listdir(folder_path)\n",
    "for file in files:\n",
    "    if os.path.isdir(os.path.join(folder_path, file)):\n",
    "        folder_path_ii = os.path.join(folder_path, file)\n",
    "        features.append(feature(folder_path_ii, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2 = []\n",
    "folder_path = \"char2line/\"\n",
    "files = os.listdir(folder_path)\n",
    "for file in files:\n",
    "    if os.path.isdir(os.path.join(folder_path, file)):\n",
    "        folder_path_ii = os.path.join(folder_path, file)\n",
    "        features2.append(feature(folder_path_ii, file))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# so sánh để đưa ra kết luận"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(binary, number, features):\n",
    "    n = 0\n",
    "    max = 0\n",
    "    i = 0\n",
    "\n",
    "    # number == 1: kí tự đang đọc là kí tự chữ số\n",
    "    if (number == 1):\n",
    "\n",
    "        # Đọc từ 0 đến 9\n",
    "        for i in range (10):\n",
    "\n",
    "            # Tính số pixel giống nhau của chữ số cần dự đoán và đặc trưng của các chữ số\n",
    "            matching_pixels = np.sum(binary == features[i])\n",
    "            total_pixels = binary.shape[0] * binary.shape[1]\n",
    "\n",
    "            # Tính % giống nhau bằng cách lấy số pixel giống nhau / tổng số pixel * 100\n",
    "            matching_percentage = matching_pixels / total_pixels * 100\n",
    "\n",
    "            # Lấy max = tỉ lệ khớp nhất của chữ số cần dự đoán với các chữ số đặc trưng, n là chữ số được dự đoán\n",
    "            if (matching_percentage>max): \n",
    "                n = i\n",
    "                max = matching_percentage\n",
    "\n",
    "    # number == 0: kí tự đang đọc là kí tự chữ cái\n",
    "    else:\n",
    "\n",
    "        # Nếu không phải chữ số thì đọc các feature chữ cái\n",
    "        for i in range(10, len(features)):\n",
    "            matching_pixels = np.sum(binary == features[i])\n",
    "            total_pixels = binary.shape[0] * binary.shape[1]\n",
    "            matching_percentage = matching_pixels / total_pixels * 100\n",
    "            if (matching_percentage>max): \n",
    "                n = i\n",
    "                max = matching_percentage\n",
    "    # print(n,max)\n",
    "    if (n == 7 and max < 65): \n",
    "        n = 1\n",
    "    # print(n, max)\n",
    "    return n, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_char(labels_list, max, type):\n",
    "    sorted_list = sorted(labels_list, key=lambda x: x[0])\n",
    "    if (len(labels_list) > max):\n",
    "        delete = len(labels_list) - max\n",
    "    else:\n",
    "        delete = 0\n",
    "    predicted = []\n",
    "    if (type == 0):\n",
    "        for i in range(len(sorted_list)):\n",
    "            x, dg, y = sorted_list[i]\n",
    "            predicted.append((i, predict(dg, 1, features), predict(dg, 0, features)))\n",
    "    \n",
    "    else:\n",
    "        for i in range(len(sorted_list)):\n",
    "            x, dg, y = sorted_list[i]\n",
    "            predicted.append((i, predict(dg, 1, features2), predict(dg, 0, features2)))\n",
    "    predicted = sorted(predicted, key=lambda x: x[1][1], reverse=True)\n",
    "    predicted_string = \"\"\n",
    "    j = 0\n",
    "    lst = [list(item) for item in predicted]\n",
    "    # print(lst)\n",
    "    if (type == 0):\n",
    "        for i in reversed(range(len(predicted))):\n",
    "            if (j == delete):\n",
    "                break\n",
    "            if (lst[i][0] < 2):\n",
    "                lst.remove(lst[i])\n",
    "                j = j + 1\n",
    "            elif (lst[i][0] > (2+ delete)):\n",
    "                lst.remove(lst[i])\n",
    "                j = j + 1\n",
    "            else:\n",
    "                if (lst[i][2][1] >= 65):\n",
    "                    lst.remove(lst[i-1])\n",
    "                    j = j + 1\n",
    "                else:\n",
    "                    lst.remove(lst[i])\n",
    "                    j = j + 1\n",
    "    if (type == 1):\n",
    "        for i in reversed(range(len(predicted))):\n",
    "            if (j == delete):\n",
    "                break\n",
    "            # print(lst[i])\n",
    "            if (lst[i][0] < 2):\n",
    "                lst.remove(lst[i])\n",
    "                j = j + 1\n",
    "            else:\n",
    "                if (lst[i][2][1] >= 65):\n",
    "                    # print(lst[i-1])\n",
    "                    lst.remove(lst[i-1])\n",
    "                    j = j + 1\n",
    "                else:\n",
    "                    # print(lst[i])\n",
    "                    lst.remove(lst[i])\n",
    "                    j = j + 1\n",
    "    if (type == 2):\n",
    "        if (delete != 0):\n",
    "            for i in range (delete):\n",
    "                lst.pop(-1)\n",
    "\n",
    "    predicted = [tuple(item) for item in lst] # chuyển lại thành tuple\n",
    "    i = 0\n",
    "    # print(predicted)\n",
    "    for item in sorted(lst, key=lambda x: x[0]):\n",
    "            i = i + 1\n",
    "            # print(item)\n",
    "            if (i == 3 and type == 0):\n",
    "                if (item[2][0] == 10):\n",
    "                    predicted_string += \"A\"\n",
    "                if (item[2][0] == 11):\n",
    "                    predicted_string += \"B\"\n",
    "                if (item[2][0] == 12):\n",
    "                    predicted_string += \"C\"\n",
    "                if (item[2][0] == 13):\n",
    "                    predicted_string += \"D\"\n",
    "                if (item[2][0] == 14):\n",
    "                    predicted_string += \"F\"\n",
    "                if (item[2][0] == 15):\n",
    "                    predicted_string += \"G\"\n",
    "                if (item[2][0] == 16):\n",
    "                    predicted_string += \"L\"\n",
    "                if (item[2][0] == 17):\n",
    "                    predicted_string += \"N\"\n",
    "                if (item[2][0] == 18):\n",
    "                    predicted_string += \"S\"\n",
    "                if (item[2][0] == 19):\n",
    "                    predicted_string += \"V\"\n",
    "                if (item[2][0] == 20):\n",
    "                    predicted_string += \"Y\"\n",
    "                if (item[2][0] == 21):\n",
    "                    predicted_string += \"Z\"\n",
    "            elif (i==3 and type == 1):\n",
    "                if (item[2][0] == 10):\n",
    "                    predicted_string += \"A\"\n",
    "                if (item[2][0] == 11):\n",
    "                    predicted_string += \"E\"\n",
    "                if (item[2][0] == 12):\n",
    "                    predicted_string += \"G\"\n",
    "            else:\n",
    "                predicted_string += str(item[1][0])\n",
    "    # print(predicted_string)\n",
    "    return predicted_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(cropped_image, type):\n",
    "    gray = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "    # Sử dụng hàm connectedComponents để tìm các vùng kết nối trên ảnh nhị phân\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    num_labels, labels = cv2.connectedComponents(binary)\n",
    "\n",
    "    d = 0\n",
    "        # Sử dụng hàm connectedComponentsWithStats để tính toán diện tích của các vùng kết nối\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary)\n",
    "    for i in range(num_labels):\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        if area < 90 or area > 1500:\n",
    "            labels[labels == i] = 0\n",
    "        else: \n",
    "            d = d+1\n",
    "    \n",
    "    x_centroids = centroids[:, 0]\n",
    "    y_centroids = centroids[:, 1]\n",
    "    \n",
    "    labels_list = []\n",
    "\n",
    "    if (d > 5):\n",
    "        # print(d)\n",
    "        for i in range(1, num_labels):\n",
    "            # Lấy thông tin của nhãn hiện tại\n",
    "            x, y, w, h, area = stats[i]\n",
    "\n",
    "            # Nếu diện tích của nhãn nằm trong khoảng từ 100 đến 1500\n",
    "            if 90 < area < 1500:\n",
    "                # Cắt ảnh của nhãn hiện tại từ ảnh gốc\n",
    "                digit_img = binary[y:y+h, x:x+w]\n",
    "                digit_img = cv2.resize(digit_img, (25,60))\n",
    "                # print(x_centroids[i], y_centroids[i])\n",
    "                labels_list.append((x_centroids[i], digit_img, y_centroids[i]))   \n",
    "                # print(labels_list)      \n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "    read_final = None\n",
    "    if (type == 1):\n",
    "        max = 8\n",
    "        read_final = read_char(labels_list, max, 0)\n",
    "        # print(s)\n",
    "    else: \n",
    "        label_distances = []\n",
    "        first_label = min(labels_list, key=lambda label: label[0])\n",
    "        first_x_centroid, first_digit_img, first_y_centroid = first_label\n",
    "        predicted = predict(first_digit_img, 1,  features2)\n",
    "        while (len(labels_list) > 8):\n",
    "            if (predicted[1] < 65):\n",
    "                for i, label in enumerate(labels_list):\n",
    "                    if label == first_label:\n",
    "                        del labels_list[i]\n",
    "                        break\n",
    "                first_label = min(labels_list, key=lambda label: label[0])\n",
    "                first_x_centroid, first_digit_img, first_y_centroid = first_label\n",
    "                predicted = predict(first_digit_img, 1, features2)\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "        line1 = []\n",
    "        line2 = []\n",
    "        i = 0\n",
    "        labels_list.sort(key=lambda x: x[0])\n",
    "        # print(labels_list)\n",
    "        for label in labels_list:\n",
    "            x_centroid, digit_img, y_centroid = label\n",
    "            distance = abs(y_centroid - first_y_centroid)\n",
    "            distance_x = abs(x_centroid - first_x_centroid)\n",
    "            label_distances.append(distance)\n",
    "            if (distance >= 6 + i*1.5):\n",
    "                line1.append(label)  \n",
    "            else:\n",
    "                line2.append(label)\n",
    "            i = i + 1\n",
    "\n",
    "        # print(len(line1), len(line2))\n",
    "        # print(label_distances)\n",
    "        max_line1 = 3\n",
    "        max_line2 = 5\n",
    "        line1 = read_char(line1, max_line1, 1)\n",
    "        line2 = read_char(line2, max_line2, 2)\n",
    "        read_final = line1 + line2\n",
    "        # print(read_final)\n",
    "\n",
    "    return read_final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# đọc ký tự trên biển số xe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPlate(image, model):\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = model(image)\n",
    "\n",
    "    for i, det in enumerate(results.xyxy[0]):\n",
    "        type = 0\n",
    "        # Lấy tọa độ bbox của vật thể thứ i\n",
    "        bbox = det[0:4].cpu().numpy()\n",
    "\n",
    "        # Cắt lấy vùng ảnh nằm trong bbox\n",
    "        cropped_image = image[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
    "        # Tính tỉ lệ chiều dài/ chiều rộng của biển số\n",
    "        ratio = (bbox[2]-bbox[0])/(bbox[3]-bbox[1])\n",
    "        if (ratio >= 2.2):\n",
    "            type = 1\n",
    "            cropped_image = cv2.resize(cropped_image, (256, 100))\n",
    "        else:\n",
    "            type = 2\n",
    "            cropped_image = cv2.resize(cropped_image, (550, 100))\n",
    "        \n",
    "        # print(\"Type: \", type)\n",
    "        read_fn = read(cropped_image, type)\n",
    "        # print(read_fn)\n",
    "        return type, read_fn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test xuất ra loại biển số (1 dòng/ 2 dòng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = \"yellow_license_plate/\" # đường dẫn đến folder chứa ảnh\n",
    "\n",
    "# type = []\n",
    "# for filename in os.listdir(folder_path):\n",
    "#     if filename.endswith(\".jpg\") or filename.endswith(\".png\"): \n",
    "#         # kiểm tra xem file có phải là ảnh jpg hoặc png không\n",
    "#         file_path = os.path.join(folder_path, filename)\n",
    "#         img = cv2.imread(file_path) # đọc ảnh bằng OpenCV\n",
    "#         # sử dụng ảnh tại đây\n",
    "#         name, extension = os.path.splitext(filename) # Tách phần đuôi của tên tệp\n",
    "#         print(\"Image: \", name)\n",
    "#         pre_final.append((name, readPlate(img, model)))\n",
    "\n",
    "# # Tạo DataFrame từ mảng\n",
    "# df = pd.DataFrame(type, columns=['Image', 'Predicted'])\n",
    "\n",
    "# # Xuất ra file CSV\n",
    "# df.to_csv('predicted_output.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test những biển số sai sót"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, '30G53507')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"33.jpg\") # đọc ảnh bằng OpenCV\n",
    "readPlate(img, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xuất ra file csv kết quả kiểm thử hình ảnh trong tập kiểm thử"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"car_long/\" # đường dẫn đến folder chứa ảnh\n",
    "\n",
    "pre_final = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"): \n",
    "        # kiểm tra xem file có phải là ảnh jpg hoặc png không\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        img = cv2.imread(file_path) # đọc ảnh bằng OpenCV\n",
    "        # sử dụng ảnh tại đây\n",
    "        name, extension = os.path.splitext(filename) # Tách phần đuôi của tên tệp\n",
    "        # print(readPlate(img, model))\n",
    "        type, pre_fn = readPlate(img, model)\n",
    "        pre_final.append((name, type, pre_fn))\n",
    "\n",
    "# Tạo DataFrame từ mảng\n",
    "df = pd.DataFrame(pre_final, columns=['Image', 'Type', 'Predicted'])\n",
    "\n",
    "# Xuất ra file CSV\n",
    "df.to_csv('predicted_output.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# đọc video kiểm thử "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[8.20958e+02, 4.59741e+02, 9.49192e+02, 5.02941e+02, 9.38341e-01, 0.00000e+00]])]\n",
      "[tensor([[810.60065, 461.98749, 939.69714, 504.00305,   0.96015,   0.00000]])]\n",
      "[tensor([[802.24969, 461.49445, 932.96320, 507.06216,   0.93370,   0.00000]])]\n",
      "[tensor([[789.38239, 463.83127, 921.75519, 509.23355,   0.94784,   0.00000]])]\n",
      "[tensor([[780.08063, 465.24307, 913.99536, 510.34506,   0.95018,   0.00000]])]\n",
      "[tensor([[765.54987, 467.07617, 904.76056, 512.17029,   0.93038,   0.00000]])]\n",
      "[tensor([[754.54291, 470.95340, 896.81110, 516.68353,   0.94119,   0.00000]])]\n",
      "[tensor([[7.41227e+02, 4.75124e+02, 8.83221e+02, 5.18177e+02, 9.16362e-01, 0.00000e+00],\n",
      "        [1.66862e+03, 3.24810e+02, 1.74412e+03, 3.68528e+02, 2.75164e-01, 0.00000e+00]])]\n",
      "[tensor([[7.41227e+02, 4.75124e+02, 8.83221e+02, 5.18177e+02, 9.16362e-01, 0.00000e+00],\n",
      "        [1.66862e+03, 3.24810e+02, 1.74412e+03, 3.68528e+02, 2.75164e-01, 0.00000e+00]])]\n",
      "[tensor([[7.27969e+02, 4.78031e+02, 8.74546e+02, 5.22588e+02, 9.56597e-01, 0.00000e+00],\n",
      "        [1.66780e+03, 3.23352e+02, 1.74372e+03, 3.68167e+02, 4.21230e-01, 0.00000e+00]])]\n",
      "[tensor([[7.27969e+02, 4.78031e+02, 8.74546e+02, 5.22588e+02, 9.56597e-01, 0.00000e+00],\n",
      "        [1.66780e+03, 3.23352e+02, 1.74372e+03, 3.68167e+02, 4.21230e-01, 0.00000e+00]])]\n",
      "[tensor([[7.15307e+02, 4.79969e+02, 8.65193e+02, 5.24946e+02, 9.25339e-01, 0.00000e+00],\n",
      "        [1.66947e+03, 3.23831e+02, 1.74175e+03, 3.68321e+02, 3.57129e-01, 0.00000e+00]])]\n",
      "[tensor([[7.15307e+02, 4.79969e+02, 8.65193e+02, 5.24946e+02, 9.25339e-01, 0.00000e+00],\n",
      "        [1.66947e+03, 3.23831e+02, 1.74175e+03, 3.68321e+02, 3.57129e-01, 0.00000e+00]])]\n",
      "[tensor([[6.99096e+02, 4.82416e+02, 8.52067e+02, 5.26891e+02, 9.41555e-01, 0.00000e+00],\n",
      "        [1.67130e+03, 3.23306e+02, 1.74191e+03, 3.68479e+02, 3.11050e-01, 0.00000e+00]])]\n",
      "[tensor([[6.99096e+02, 4.82416e+02, 8.52067e+02, 5.26891e+02, 9.41555e-01, 0.00000e+00],\n",
      "        [1.67130e+03, 3.23306e+02, 1.74191e+03, 3.68479e+02, 3.11050e-01, 0.00000e+00]])]\n",
      "[tensor([[684.01703, 482.89529, 835.90399, 530.15784,   0.93551,   0.00000]])]\n",
      "[tensor([[668.05023, 484.99841, 820.59430, 533.11066,   0.89619,   0.00000]])]\n",
      "[tensor([[647.58490, 487.39655, 805.57001, 537.93292,   0.90487,   0.00000]])]\n",
      "[tensor([[631.09277, 489.48297, 787.99261, 540.17999,   0.92296,   0.00000]])]\n",
      "[tensor([[608.78503, 490.46616, 771.69257, 543.88770,   0.85758,   0.00000]])]\n",
      "[tensor([[591.09302, 494.16650, 756.29321, 546.11835,   0.88885,   0.00000]])]\n",
      "[tensor([[574.64209, 497.53082, 741.71265, 551.37634,   0.94569,   0.00000]])]\n",
      "[tensor([[556.95990, 502.60950, 726.86365, 556.39935,   0.93751,   0.00000]])]\n",
      "[tensor([[541.91034, 507.63385, 710.62659, 561.28070,   0.90654,   0.00000]])]\n",
      "[tensor([[524.74823, 512.02332, 696.77972, 566.36017,   0.93322,   0.00000]])]\n",
      "[tensor([[5.03739e+02, 5.14394e+02, 6.81393e+02, 5.69678e+02, 9.25548e-01, 0.00000e+00],\n",
      "        [1.48361e+03, 3.91061e+02, 1.55379e+03, 4.16637e+02, 2.60003e-01, 0.00000e+00]])]\n",
      "[tensor([[5.03739e+02, 5.14394e+02, 6.81393e+02, 5.69678e+02, 9.25548e-01, 0.00000e+00],\n",
      "        [1.48361e+03, 3.91061e+02, 1.55379e+03, 4.16637e+02, 2.60003e-01, 0.00000e+00]])]\n",
      "[tensor([[4.85685e+02, 5.16805e+02, 6.68021e+02, 5.73720e+02, 9.27614e-01, 0.00000e+00],\n",
      "        [1.48678e+03, 3.92425e+02, 1.55051e+03, 4.20233e+02, 3.56282e-01, 0.00000e+00]])]\n",
      "[tensor([[4.85685e+02, 5.16805e+02, 6.68021e+02, 5.73720e+02, 9.27614e-01, 0.00000e+00],\n",
      "        [1.48678e+03, 3.92425e+02, 1.55051e+03, 4.20233e+02, 3.56282e-01, 0.00000e+00]])]\n",
      "[tensor([[4.67830e+02, 5.21076e+02, 6.51523e+02, 5.77392e+02, 9.63701e-01, 0.00000e+00],\n",
      "        [1.48220e+03, 3.92603e+02, 1.55506e+03, 4.19532e+02, 4.54637e-01, 0.00000e+00]])]\n",
      "[tensor([[4.67830e+02, 5.21076e+02, 6.51523e+02, 5.77392e+02, 9.63701e-01, 0.00000e+00],\n",
      "        [1.48220e+03, 3.92603e+02, 1.55506e+03, 4.19532e+02, 4.54637e-01, 0.00000e+00]])]\n",
      "[tensor([[4.45220e+02, 5.23747e+02, 6.31655e+02, 5.80468e+02, 9.65244e-01, 0.00000e+00],\n",
      "        [1.48181e+03, 3.92883e+02, 1.55387e+03, 4.19944e+02, 4.68144e-01, 0.00000e+00],\n",
      "        [5.67159e+02, 1.01842e+02, 7.81534e+02, 1.61188e+02, 3.03805e-01, 0.00000e+00]])]\n",
      "[tensor([[4.45220e+02, 5.23747e+02, 6.31655e+02, 5.80468e+02, 9.65244e-01, 0.00000e+00],\n",
      "        [1.48181e+03, 3.92883e+02, 1.55387e+03, 4.19944e+02, 4.68144e-01, 0.00000e+00],\n",
      "        [5.67159e+02, 1.01842e+02, 7.81534e+02, 1.61188e+02, 3.03805e-01, 0.00000e+00]])]\n",
      "[tensor([[4.45220e+02, 5.23747e+02, 6.31655e+02, 5.80468e+02, 9.65244e-01, 0.00000e+00],\n",
      "        [1.48181e+03, 3.92883e+02, 1.55387e+03, 4.19944e+02, 4.68144e-01, 0.00000e+00],\n",
      "        [5.67159e+02, 1.01842e+02, 7.81534e+02, 1.61188e+02, 3.03805e-01, 0.00000e+00]])]\n",
      "[tensor([[4.24959e+02, 5.25896e+02, 6.12052e+02, 5.82788e+02, 9.61754e-01, 0.00000e+00],\n",
      "        [1.48110e+03, 3.92905e+02, 1.55225e+03, 4.20078e+02, 5.71992e-01, 0.00000e+00]])]\n",
      "[tensor([[4.24959e+02, 5.25896e+02, 6.12052e+02, 5.82788e+02, 9.61754e-01, 0.00000e+00],\n",
      "        [1.48110e+03, 3.92905e+02, 1.55225e+03, 4.20078e+02, 5.71992e-01, 0.00000e+00]])]\n",
      "[tensor([[4.00566e+02, 5.27901e+02, 5.92037e+02, 5.85642e+02, 9.39532e-01, 0.00000e+00],\n",
      "        [1.47942e+03, 3.92348e+02, 1.54967e+03, 4.19582e+02, 5.91139e-01, 0.00000e+00],\n",
      "        [5.33268e+02, 9.73238e+01, 7.52195e+02, 1.54887e+02, 3.51047e-01, 0.00000e+00]])]\n",
      "[tensor([[4.00566e+02, 5.27901e+02, 5.92037e+02, 5.85642e+02, 9.39532e-01, 0.00000e+00],\n",
      "        [1.47942e+03, 3.92348e+02, 1.54967e+03, 4.19582e+02, 5.91139e-01, 0.00000e+00],\n",
      "        [5.33268e+02, 9.73238e+01, 7.52195e+02, 1.54887e+02, 3.51047e-01, 0.00000e+00]])]\n",
      "[tensor([[4.00566e+02, 5.27901e+02, 5.92037e+02, 5.85642e+02, 9.39532e-01, 0.00000e+00],\n",
      "        [1.47942e+03, 3.92348e+02, 1.54967e+03, 4.19582e+02, 5.91139e-01, 0.00000e+00],\n",
      "        [5.33268e+02, 9.73238e+01, 7.52195e+02, 1.54887e+02, 3.51047e-01, 0.00000e+00]])]\n",
      "[tensor([[3.80517e+02, 5.31541e+02, 5.75551e+02, 5.91932e+02, 8.90072e-01, 0.00000e+00],\n",
      "        [1.48109e+03, 3.93422e+02, 1.54912e+03, 4.21945e+02, 6.08299e-01, 0.00000e+00]])]\n",
      "[tensor([[3.80517e+02, 5.31541e+02, 5.75551e+02, 5.91932e+02, 8.90072e-01, 0.00000e+00],\n",
      "        [1.48109e+03, 3.93422e+02, 1.54912e+03, 4.21945e+02, 6.08299e-01, 0.00000e+00]])]\n",
      "[tensor([[3.59563e+02, 5.33973e+02, 5.54890e+02, 5.94651e+02, 9.03037e-01, 0.00000e+00],\n",
      "        [1.47879e+03, 3.92848e+02, 1.54926e+03, 4.20311e+02, 5.97092e-01, 0.00000e+00],\n",
      "        [4.98999e+02, 8.99677e+01, 7.34638e+02, 1.49845e+02, 3.80903e-01, 0.00000e+00]])]\n",
      "[tensor([[3.59563e+02, 5.33973e+02, 5.54890e+02, 5.94651e+02, 9.03037e-01, 0.00000e+00],\n",
      "        [1.47879e+03, 3.92848e+02, 1.54926e+03, 4.20311e+02, 5.97092e-01, 0.00000e+00],\n",
      "        [4.98999e+02, 8.99677e+01, 7.34638e+02, 1.49845e+02, 3.80903e-01, 0.00000e+00]])]\n",
      "[tensor([[3.59563e+02, 5.33973e+02, 5.54890e+02, 5.94651e+02, 9.03037e-01, 0.00000e+00],\n",
      "        [1.47879e+03, 3.92848e+02, 1.54926e+03, 4.20311e+02, 5.97092e-01, 0.00000e+00],\n",
      "        [4.98999e+02, 8.99677e+01, 7.34638e+02, 1.49845e+02, 3.80903e-01, 0.00000e+00]])]\n",
      "[tensor([[3.36298e+02, 5.36126e+02, 5.33461e+02, 5.98323e+02, 9.33839e-01, 0.00000e+00],\n",
      "        [1.47870e+03, 3.93020e+02, 1.54692e+03, 4.20966e+02, 6.28258e-01, 0.00000e+00],\n",
      "        [4.80396e+02, 8.77519e+01, 7.13681e+02, 1.45131e+02, 2.64113e-01, 0.00000e+00]])]\n",
      "[tensor([[3.36298e+02, 5.36126e+02, 5.33461e+02, 5.98323e+02, 9.33839e-01, 0.00000e+00],\n",
      "        [1.47870e+03, 3.93020e+02, 1.54692e+03, 4.20966e+02, 6.28258e-01, 0.00000e+00],\n",
      "        [4.80396e+02, 8.77519e+01, 7.13681e+02, 1.45131e+02, 2.64113e-01, 0.00000e+00]])]\n",
      "[tensor([[3.36298e+02, 5.36126e+02, 5.33461e+02, 5.98323e+02, 9.33839e-01, 0.00000e+00],\n",
      "        [1.47870e+03, 3.93020e+02, 1.54692e+03, 4.20966e+02, 6.28258e-01, 0.00000e+00],\n",
      "        [4.80396e+02, 8.77519e+01, 7.13681e+02, 1.45131e+02, 2.64113e-01, 0.00000e+00]])]\n",
      "[tensor([[3.12464e+02, 5.40142e+02, 5.12063e+02, 6.04882e+02, 9.32052e-01, 0.00000e+00],\n",
      "        [1.47761e+03, 3.93512e+02, 1.54590e+03, 4.23152e+02, 7.38411e-01, 0.00000e+00],\n",
      "        [4.65220e+02, 8.41202e+01, 6.96882e+02, 1.44211e+02, 3.51604e-01, 0.00000e+00]])]\n",
      "[tensor([[3.12464e+02, 5.40142e+02, 5.12063e+02, 6.04882e+02, 9.32052e-01, 0.00000e+00],\n",
      "        [1.47761e+03, 3.93512e+02, 1.54590e+03, 4.23152e+02, 7.38411e-01, 0.00000e+00],\n",
      "        [4.65220e+02, 8.41202e+01, 6.96882e+02, 1.44211e+02, 3.51604e-01, 0.00000e+00]])]\n",
      "[tensor([[3.12464e+02, 5.40142e+02, 5.12063e+02, 6.04882e+02, 9.32052e-01, 0.00000e+00],\n",
      "        [1.47761e+03, 3.93512e+02, 1.54590e+03, 4.23152e+02, 7.38411e-01, 0.00000e+00],\n",
      "        [4.65220e+02, 8.41202e+01, 6.96882e+02, 1.44211e+02, 3.51604e-01, 0.00000e+00]])]\n",
      "[tensor([[2.87284e+02, 5.45613e+02, 4.93299e+02, 6.10393e+02, 9.38290e-01, 0.00000e+00],\n",
      "        [1.47817e+03, 3.95836e+02, 1.54778e+03, 4.24283e+02, 7.30233e-01, 0.00000e+00]])]\n",
      "[tensor([[2.87284e+02, 5.45613e+02, 4.93299e+02, 6.10393e+02, 9.38290e-01, 0.00000e+00],\n",
      "        [1.47817e+03, 3.95836e+02, 1.54778e+03, 4.24283e+02, 7.30233e-01, 0.00000e+00]])]\n",
      "[tensor([[2.63842e+02, 5.49120e+02, 4.71799e+02, 6.13912e+02, 9.31161e-01, 0.00000e+00],\n",
      "        [1.47915e+03, 3.95752e+02, 1.54992e+03, 4.24154e+02, 7.29874e-01, 0.00000e+00],\n",
      "        [4.26564e+02, 7.46435e+01, 6.65318e+02, 1.35950e+02, 3.78729e-01, 0.00000e+00]])]\n",
      "[tensor([[2.63842e+02, 5.49120e+02, 4.71799e+02, 6.13912e+02, 9.31161e-01, 0.00000e+00],\n",
      "        [1.47915e+03, 3.95752e+02, 1.54992e+03, 4.24154e+02, 7.29874e-01, 0.00000e+00],\n",
      "        [4.26564e+02, 7.46435e+01, 6.65318e+02, 1.35950e+02, 3.78729e-01, 0.00000e+00]])]\n",
      "[tensor([[2.63842e+02, 5.49120e+02, 4.71799e+02, 6.13912e+02, 9.31161e-01, 0.00000e+00],\n",
      "        [1.47915e+03, 3.95752e+02, 1.54992e+03, 4.24154e+02, 7.29874e-01, 0.00000e+00],\n",
      "        [4.26564e+02, 7.46435e+01, 6.65318e+02, 1.35950e+02, 3.78729e-01, 0.00000e+00]])]\n",
      "[tensor([[2.34902e+02, 5.52821e+02, 4.48567e+02, 6.19645e+02, 9.19250e-01, 0.00000e+00],\n",
      "        [1.47793e+03, 3.94612e+02, 1.54965e+03, 4.23196e+02, 7.16512e-01, 0.00000e+00]])]\n",
      "[tensor([[2.34902e+02, 5.52821e+02, 4.48567e+02, 6.19645e+02, 9.19250e-01, 0.00000e+00],\n",
      "        [1.47793e+03, 3.94612e+02, 1.54965e+03, 4.23196e+02, 7.16512e-01, 0.00000e+00]])]\n",
      "[tensor([[2.07660e+02, 5.56367e+02, 4.28256e+02, 6.24972e+02, 9.16560e-01, 0.00000e+00],\n",
      "        [1.47805e+03, 3.94619e+02, 1.55098e+03, 4.23694e+02, 6.89532e-01, 0.00000e+00],\n",
      "        [3.81813e+02, 6.33361e+01, 6.33811e+02, 1.27575e+02, 2.92692e-01, 0.00000e+00]])]\n",
      "[tensor([[2.07660e+02, 5.56367e+02, 4.28256e+02, 6.24972e+02, 9.16560e-01, 0.00000e+00],\n",
      "        [1.47805e+03, 3.94619e+02, 1.55098e+03, 4.23694e+02, 6.89532e-01, 0.00000e+00],\n",
      "        [3.81813e+02, 6.33361e+01, 6.33811e+02, 1.27575e+02, 2.92692e-01, 0.00000e+00]])]\n",
      "[tensor([[2.07660e+02, 5.56367e+02, 4.28256e+02, 6.24972e+02, 9.16560e-01, 0.00000e+00],\n",
      "        [1.47805e+03, 3.94619e+02, 1.55098e+03, 4.23694e+02, 6.89532e-01, 0.00000e+00],\n",
      "        [3.81813e+02, 6.33361e+01, 6.33811e+02, 1.27575e+02, 2.92692e-01, 0.00000e+00]])]\n",
      "[tensor([[1.79030e+02, 5.59531e+02, 4.01266e+02, 6.30246e+02, 9.27448e-01, 0.00000e+00],\n",
      "        [1.47843e+03, 3.95233e+02, 1.55179e+03, 4.24640e+02, 6.74753e-01, 0.00000e+00],\n",
      "        [3.62568e+02, 6.10605e+01, 6.19271e+02, 1.30283e+02, 2.63343e-01, 0.00000e+00]])]\n",
      "[tensor([[1.79030e+02, 5.59531e+02, 4.01266e+02, 6.30246e+02, 9.27448e-01, 0.00000e+00],\n",
      "        [1.47843e+03, 3.95233e+02, 1.55179e+03, 4.24640e+02, 6.74753e-01, 0.00000e+00],\n",
      "        [3.62568e+02, 6.10605e+01, 6.19271e+02, 1.30283e+02, 2.63343e-01, 0.00000e+00]])]\n",
      "[tensor([[1.79030e+02, 5.59531e+02, 4.01266e+02, 6.30246e+02, 9.27448e-01, 0.00000e+00],\n",
      "        [1.47843e+03, 3.95233e+02, 1.55179e+03, 4.24640e+02, 6.74753e-01, 0.00000e+00],\n",
      "        [3.62568e+02, 6.10605e+01, 6.19271e+02, 1.30283e+02, 2.63343e-01, 0.00000e+00]])]\n",
      "[tensor([[1.51286e+02, 5.65337e+02, 3.78232e+02, 6.33832e+02, 9.25199e-01, 0.00000e+00],\n",
      "        [1.47931e+03, 3.95690e+02, 1.55273e+03, 4.24601e+02, 6.75911e-01, 0.00000e+00]])]\n",
      "[tensor([[1.51286e+02, 5.65337e+02, 3.78232e+02, 6.33832e+02, 9.25199e-01, 0.00000e+00],\n",
      "        [1.47931e+03, 3.95690e+02, 1.55273e+03, 4.24601e+02, 6.75911e-01, 0.00000e+00]])]\n",
      "[tensor([[1.21526e+02, 5.69658e+02, 3.53591e+02, 6.39540e+02, 9.19702e-01, 0.00000e+00],\n",
      "        [1.47747e+03, 3.93742e+02, 1.55499e+03, 4.23463e+02, 7.28719e-01, 0.00000e+00],\n",
      "        [3.15627e+02, 4.57328e+01, 5.75282e+02, 1.15542e+02, 4.43252e-01, 0.00000e+00]])]\n",
      "[tensor([[1.21526e+02, 5.69658e+02, 3.53591e+02, 6.39540e+02, 9.19702e-01, 0.00000e+00],\n",
      "        [1.47747e+03, 3.93742e+02, 1.55499e+03, 4.23463e+02, 7.28719e-01, 0.00000e+00],\n",
      "        [3.15627e+02, 4.57328e+01, 5.75282e+02, 1.15542e+02, 4.43252e-01, 0.00000e+00]])]\n",
      "[tensor([[1.21526e+02, 5.69658e+02, 3.53591e+02, 6.39540e+02, 9.19702e-01, 0.00000e+00],\n",
      "        [1.47747e+03, 3.93742e+02, 1.55499e+03, 4.23463e+02, 7.28719e-01, 0.00000e+00],\n",
      "        [3.15627e+02, 4.57328e+01, 5.75282e+02, 1.15542e+02, 4.43252e-01, 0.00000e+00]])]\n",
      "[tensor([[9.09125e+01, 5.73254e+02, 3.23911e+02, 6.44538e+02, 9.23532e-01, 0.00000e+00],\n",
      "        [1.47711e+03, 3.93215e+02, 1.55490e+03, 4.23218e+02, 7.29090e-01, 0.00000e+00],\n",
      "        [2.90412e+02, 3.81957e+01, 5.54509e+02, 1.08335e+02, 3.80087e-01, 0.00000e+00]])]\n",
      "[tensor([[9.09125e+01, 5.73254e+02, 3.23911e+02, 6.44538e+02, 9.23532e-01, 0.00000e+00],\n",
      "        [1.47711e+03, 3.93215e+02, 1.55490e+03, 4.23218e+02, 7.29090e-01, 0.00000e+00],\n",
      "        [2.90412e+02, 3.81957e+01, 5.54509e+02, 1.08335e+02, 3.80087e-01, 0.00000e+00]])]\n",
      "[tensor([[9.09125e+01, 5.73254e+02, 3.23911e+02, 6.44538e+02, 9.23532e-01, 0.00000e+00],\n",
      "        [1.47711e+03, 3.93215e+02, 1.55490e+03, 4.23218e+02, 7.29090e-01, 0.00000e+00],\n",
      "        [2.90412e+02, 3.81957e+01, 5.54509e+02, 1.08335e+02, 3.80087e-01, 0.00000e+00]])]\n",
      "[tensor([[5.73644e+01, 5.78869e+02, 2.94364e+02, 6.50722e+02, 9.23687e-01, 0.00000e+00],\n",
      "        [1.47666e+03, 3.93158e+02, 1.55450e+03, 4.22984e+02, 7.82687e-01, 0.00000e+00],\n",
      "        [2.62437e+02, 2.82111e+01, 5.46945e+02, 1.09452e+02, 4.44292e-01, 0.00000e+00]])]\n",
      "[tensor([[5.73644e+01, 5.78869e+02, 2.94364e+02, 6.50722e+02, 9.23687e-01, 0.00000e+00],\n",
      "        [1.47666e+03, 3.93158e+02, 1.55450e+03, 4.22984e+02, 7.82687e-01, 0.00000e+00],\n",
      "        [2.62437e+02, 2.82111e+01, 5.46945e+02, 1.09452e+02, 4.44292e-01, 0.00000e+00]])]\n",
      "[tensor([[5.73644e+01, 5.78869e+02, 2.94364e+02, 6.50722e+02, 9.23687e-01, 0.00000e+00],\n",
      "        [1.47666e+03, 3.93158e+02, 1.55450e+03, 4.22984e+02, 7.82687e-01, 0.00000e+00],\n",
      "        [2.62437e+02, 2.82111e+01, 5.46945e+02, 1.09452e+02, 4.44292e-01, 0.00000e+00]])]\n",
      "[tensor([[2.42445e+01, 5.82849e+02, 2.67502e+02, 6.59052e+02, 9.16025e-01, 0.00000e+00],\n",
      "        [1.47779e+03, 3.94667e+02, 1.55463e+03, 4.25184e+02, 7.62042e-01, 0.00000e+00],\n",
      "        [2.46763e+02, 2.58574e+01, 5.32022e+02, 1.04204e+02, 3.83076e-01, 0.00000e+00]])]\n",
      "[tensor([[2.42445e+01, 5.82849e+02, 2.67502e+02, 6.59052e+02, 9.16025e-01, 0.00000e+00],\n",
      "        [1.47779e+03, 3.94667e+02, 1.55463e+03, 4.25184e+02, 7.62042e-01, 0.00000e+00],\n",
      "        [2.46763e+02, 2.58574e+01, 5.32022e+02, 1.04204e+02, 3.83076e-01, 0.00000e+00]])]\n",
      "[tensor([[2.42445e+01, 5.82849e+02, 2.67502e+02, 6.59052e+02, 9.16025e-01, 0.00000e+00],\n",
      "        [1.47779e+03, 3.94667e+02, 1.55463e+03, 4.25184e+02, 7.62042e-01, 0.00000e+00],\n",
      "        [2.46763e+02, 2.58574e+01, 5.32022e+02, 1.04204e+02, 3.83076e-01, 0.00000e+00]])]\n",
      "[tensor([[0.00000e+00, 5.85131e+02, 2.36369e+02, 6.66479e+02, 9.32105e-01, 0.00000e+00],\n",
      "        [1.47705e+03, 3.95034e+02, 1.55647e+03, 4.25502e+02, 7.64359e-01, 0.00000e+00]])]\n",
      "[tensor([[0.00000e+00, 5.85131e+02, 2.36369e+02, 6.66479e+02, 9.32105e-01, 0.00000e+00],\n",
      "        [1.47705e+03, 3.95034e+02, 1.55647e+03, 4.25502e+02, 7.64359e-01, 0.00000e+00]])]\n",
      "[tensor([[0.00000e+00, 5.90563e+02, 2.02539e+02, 6.71535e+02, 9.36507e-01, 0.00000e+00],\n",
      "        [1.47647e+03, 3.94850e+02, 1.55732e+03, 4.25940e+02, 7.74704e-01, 0.00000e+00]])]\n",
      "[tensor([[0.00000e+00, 5.90563e+02, 2.02539e+02, 6.71535e+02, 9.36507e-01, 0.00000e+00],\n",
      "        [1.47647e+03, 3.94850e+02, 1.55732e+03, 4.25940e+02, 7.74704e-01, 0.00000e+00]])]\n",
      "[tensor([[3.13059e-01, 5.92175e+02, 1.70108e+02, 6.78843e+02, 9.45774e-01, 0.00000e+00],\n",
      "        [1.47606e+03, 3.94862e+02, 1.55650e+03, 4.25926e+02, 7.94189e-01, 0.00000e+00]])]\n",
      "[tensor([[3.13059e-01, 5.92175e+02, 1.70108e+02, 6.78843e+02, 9.45774e-01, 0.00000e+00],\n",
      "        [1.47606e+03, 3.94862e+02, 1.55650e+03, 4.25926e+02, 7.94189e-01, 0.00000e+00]])]\n",
      "[tensor([[1.09629e+00, 6.01484e+02, 1.35058e+02, 6.84109e+02, 9.38027e-01, 0.00000e+00],\n",
      "        [1.47512e+03, 3.93479e+02, 1.55702e+03, 4.25355e+02, 8.36147e-01, 0.00000e+00]])]\n",
      "[tensor([[1.09629e+00, 6.01484e+02, 1.35058e+02, 6.84109e+02, 9.38027e-01, 0.00000e+00],\n",
      "        [1.47512e+03, 3.93479e+02, 1.55702e+03, 4.25355e+02, 8.36147e-01, 0.00000e+00]])]\n",
      "[tensor([[1.47970e+00, 6.06506e+02, 9.80297e+01, 6.91786e+02, 9.10341e-01, 0.00000e+00],\n",
      "        [1.47391e+03, 3.93261e+02, 1.55670e+03, 4.25548e+02, 8.40607e-01, 0.00000e+00],\n",
      "        [1.01789e+02, 7.71887e-01, 4.05658e+02, 7.75214e+01, 3.37767e-01, 0.00000e+00]])]\n",
      "[tensor([[1.47970e+00, 6.06506e+02, 9.80297e+01, 6.91786e+02, 9.10341e-01, 0.00000e+00],\n",
      "        [1.47391e+03, 3.93261e+02, 1.55670e+03, 4.25548e+02, 8.40607e-01, 0.00000e+00],\n",
      "        [1.01789e+02, 7.71887e-01, 4.05658e+02, 7.75214e+01, 3.37767e-01, 0.00000e+00]])]\n",
      "[tensor([[1.47970e+00, 6.06506e+02, 9.80297e+01, 6.91786e+02, 9.10341e-01, 0.00000e+00],\n",
      "        [1.47391e+03, 3.93261e+02, 1.55670e+03, 4.25548e+02, 8.40607e-01, 0.00000e+00],\n",
      "        [1.01789e+02, 7.71887e-01, 4.05658e+02, 7.75214e+01, 3.37767e-01, 0.00000e+00]])]\n",
      "[tensor([[1.47214e+03, 3.94155e+02, 1.55532e+03, 4.26133e+02, 8.40013e-01, 0.00000e+00],\n",
      "        [6.57383e-01, 6.06775e+02, 5.52523e+01, 7.00742e+02, 8.29843e-01, 0.00000e+00],\n",
      "        [6.64089e+01, 0.00000e+00, 3.66016e+02, 7.08570e+01, 3.10926e-01, 0.00000e+00]])]\n",
      "[tensor([[1.47214e+03, 3.94155e+02, 1.55532e+03, 4.26133e+02, 8.40013e-01, 0.00000e+00],\n",
      "        [6.57383e-01, 6.06775e+02, 5.52523e+01, 7.00742e+02, 8.29843e-01, 0.00000e+00],\n",
      "        [6.64089e+01, 0.00000e+00, 3.66016e+02, 7.08570e+01, 3.10926e-01, 0.00000e+00]])]\n",
      "[tensor([[1.47214e+03, 3.94155e+02, 1.55532e+03, 4.26133e+02, 8.40013e-01, 0.00000e+00],\n",
      "        [6.57383e-01, 6.06775e+02, 5.52523e+01, 7.00742e+02, 8.29843e-01, 0.00000e+00],\n",
      "        [6.64089e+01, 0.00000e+00, 3.66016e+02, 7.08570e+01, 3.10926e-01, 0.00000e+00]])]\n",
      "[tensor([[1.47160e+03, 3.93362e+02, 1.55584e+03, 4.25873e+02, 8.53221e-01, 0.00000e+00],\n",
      "        [3.29382e+01, 0.00000e+00, 3.43419e+02, 6.56380e+01, 6.57561e-01, 0.00000e+00]])]\n",
      "[tensor([[1.47160e+03, 3.93362e+02, 1.55584e+03, 4.25873e+02, 8.53221e-01, 0.00000e+00],\n",
      "        [3.29382e+01, 0.00000e+00, 3.43419e+02, 6.56380e+01, 6.57561e-01, 0.00000e+00]])]\n",
      "[tensor([[1.47167e+03, 3.94005e+02, 1.55364e+03, 4.26227e+02, 8.25442e-01, 0.00000e+00]])]\n",
      "[tensor([[1.47043e+03, 3.93708e+02, 1.55330e+03, 4.26316e+02, 8.45625e-01, 0.00000e+00]])]\n",
      "[tensor([[1.46979e+03, 3.94884e+02, 1.55581e+03, 4.26993e+02, 8.42214e-01, 0.00000e+00]])]\n",
      "[tensor([[1.46816e+03, 3.94801e+02, 1.55530e+03, 4.27997e+02, 8.68428e-01, 0.00000e+00]])]\n",
      "[tensor([[1.46534e+03, 3.95147e+02, 1.55294e+03, 4.28400e+02, 8.68973e-01, 0.00000e+00]])]\n",
      "[tensor([[1.46149e+03, 3.96003e+02, 1.54862e+03, 4.28744e+02, 8.55295e-01, 0.00000e+00]])]\n",
      "[tensor([[1.46043e+03, 3.95920e+02, 1.54783e+03, 4.28146e+02, 8.32355e-01, 0.00000e+00]])]\n",
      "[tensor([[1.45392e+03, 3.95821e+02, 1.54472e+03, 4.29006e+02, 8.38012e-01, 0.00000e+00]])]\n",
      "[tensor([[1.45199e+03, 3.96508e+02, 1.54204e+03, 4.28924e+02, 8.16331e-01, 0.00000e+00]])]\n",
      "[tensor([[1.44896e+03, 3.96213e+02, 1.53911e+03, 4.29038e+02, 8.47063e-01, 0.00000e+00]])]\n"
     ]
    }
   ],
   "source": [
    "# Tạo một đối tượng VideoCapture để đọc video\n",
    "cap = cv2.VideoCapture('test.MOV')\n",
    "\n",
    "# Lấy kích thước khung hình của video\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Tạo đối tượng VideoWriter để ghi video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('processed_video.mp4', fourcc, 30, (width, height))\n",
    "# Đọc từng khung hình của video, xử lý và ghi lại\n",
    "result_s = ''\n",
    "r = 0\n",
    "\n",
    "with open(\"license_plates_history.txt\", \"w\") as file:\n",
    "    file.write('')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Xử lý khung hình ở đây\n",
    "    processed_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = model(processed_frame)\n",
    "    \n",
    "    if len(results.pred[0]) >= 1:\n",
    "        if (results.pred[0][0][2].item() - results.pred[0][0][0].item() < 150 and r == 1):\n",
    "            r = 0\n",
    "        for i in range (len(results.pred[0])):\n",
    "            accuracy = float(results.pred[0][i][4].item())\n",
    "            print(results.pred)\n",
    "            if (accuracy >= 0.92 and (results.pred[0][i][2].item() - results.pred[0][i][0].item()) >= 200 and r == 0):\n",
    "                    k, result_s = readPlate(processed_frame,model)\n",
    "                    if (result_s == \"\"):\n",
    "                        r = 0\n",
    "                    else:\n",
    "                        r = 1\n",
    "                    with open('license_plates_history.txt', 'a') as file:\n",
    "                        file.write(result_s + '\\n')\n",
    "    # Vẽ chuỗi result_s lên khung hình results\n",
    "    cv2.putText(results.render()[0], result_s, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(results.render()[0], str(r), (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    # Ghi khung hình đã xử lý vào đối tượng VideoWriter\n",
    "    out.write(cv2.cvtColor(results.render()[0], cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # # Hiển thị khung hình đã xử lý\n",
    "    cv2.imshow('Processed Frame', cv2.cvtColor(results.render()[0], cv2.COLOR_RGB2BGR))\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Giải phóng các tài nguyên và đóng các cửa sổ hiển thị\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Đọc file CSV vào DataFrame\n",
    "df = pd.read_csv('predicted_output.csv')\n",
    "\n",
    "# Sắp xếp DataFrame theo cột số\n",
    "df_sorted = df.sort_values(by='Image', ascending=True)\n",
    "\n",
    "# Lưu lại kết quả vào file CSV\n",
    "df_sorted.to_csv('predicted_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "# # Đường dẫn đến file csv\n",
    "# file_path = 'true_output.csv'\n",
    "\n",
    "# # Danh sách các dòng mới cần thêm\n",
    "# new_rows = [\n",
    "#     ['3', '2', '29E01526'],\n",
    "#     ['5', '2', '27A04290'],\n",
    "#     ['6', '2', '27A04290'],\n",
    "#     ['9', '2', '29E01526'],\n",
    "#     ['10', '2', '30E82594'],\n",
    "#     ['11', '2', '29E02000'],\n",
    "#     ['12', '2', '81A10048'],\n",
    "#     ['14', '2', '24E00001'],\n",
    "#     ['20', '2', '81A10048'],\n",
    "#     ['21', '2', '49E00001'],\n",
    "#     ['25', '2', '37A74953'],\n",
    "#     ['26', '2', '18E00003'],\n",
    "#     ['27', '2', '24E00001'],\n",
    "#     ['28', '2', '61A88888'],\n",
    "#     ['37', '2', '61A88888']\n",
    "# ]\n",
    "\n",
    "# # Đọc nội dung file csv vào list\n",
    "# with open(file_path, 'r') as file:\n",
    "#     reader = csv.reader(file)\n",
    "#     rows = list(reader)\n",
    "\n",
    "# # Thêm các dòng mới vào list\n",
    "# for new_row in new_rows:\n",
    "#     rows.append(new_row)\n",
    "\n",
    "# # Sắp xếp lại các cột\n",
    "# rows = sorted(rows, key=lambda x: (x[0], x[1], x[2]))\n",
    "\n",
    "# # Ghi lại nội dung list vào file csv\n",
    "# with open(file_path, 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc hai file CSV và lưu chúng vào hai DataFrame\n",
    "df1 = pd.read_csv('predicted_output.csv')\n",
    "df2 = pd.read_csv('true_output.csv')\n",
    "\n",
    "# Kết hợp hai DataFrame và lấy các cột cần thiết\n",
    "merged_df = pd.merge(df1[['Image', 'Predicted']], df2[['Image', 'True']], on='Image')\n",
    "\n",
    "merged_df['Diff'] = merged_df.apply(lambda row: 0 if row['Predicted'] == row['True'] else 1, axis=1)\n",
    "\n",
    "# Thêm cột Predict dựa trên giá trị của cột thứ 2\n",
    "merged_df['Predict'] = merged_df['Predicted'].apply(lambda x: 0 if x == \"0\" else 1)\n",
    "\n",
    "# Thêm cột Miss để kiểm tra độ dài khác nhau giữa hai cột 'Predicted' và 'True'\n",
    "merged_df['Miss'] = merged_df.apply(lambda row: 1 if (not pd.isnull(row['Predicted'])) and (not pd.isnull(row['True'])) and len(str(row['Predicted'])) - len(str(row['True'])) != 0 else 0, axis=1)\n",
    "\n",
    "# Lưu các cột vào file CSV\n",
    "merged_df.to_csv('Evaluate.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số ảnh kiểm thử:  489\n",
      "Tỉ lệ không thể nhận diện biển số: 0.00%\n",
      "Tỉ lệ đọc sai biển số: 5.52%\n",
      "Tỉ lệ đọc thiếu chữ số: 1.84%\n",
      "Tỉ lệ biển số đọc đúng: 92.64%\n",
      "     Image Predicted      True  Diff  Predict  Miss\n",
      "45     509  51A89711  51A89714     1        1     0\n",
      "49     554    54Y210  54A72110     1        1     1\n",
      "50     555       NaN  54A72110     1        1     0\n",
      "57     647  51F24483  51F24403     1        1     0\n",
      "67     782  30V39931   30V3993     1        1     1\n",
      "68     783  30V39931   30V3993     1        1     1\n",
      "82    1961       NaN  51A85325     1        1     0\n",
      "134   3820  51B21666  51D21666     1        1     0\n",
      "158   5347  51G25182  51G25181     1        1     0\n",
      "198   6897    51Z210  51A72110     1        1     1\n",
      "200   6905  51A19642  51A96141     1        1     0\n",
      "212   7078  28A51796  29A51796     1        1     0\n",
      "221   7214   15A5380  51F15380     1        1     1\n",
      "222   7215   15A5381  51F15380     1        1     1\n",
      "249   8814  51F09881  51F59881     1        1     0\n",
      "250   8815  51F54988  51F59881     1        1     0\n",
      "261   8967  51D30343  51F63034     1        1     0\n",
      "268   9049       NaN  51A72110     1        1     0\n",
      "270   9057  51A91614  51A96141     1        1     0\n",
      "272   9059  51A96142  51A96141     1        1     0\n",
      "306   9834  31A41711  51F58214     1        1     0\n",
      "332  11278  48A02666  48A02866     1        1     0\n",
      "333  11279  48A02868  48A02866     1        1     0\n",
      "338  11509  43A18850  43A18650     1        1     0\n",
      "341  11664  41A08546  41A06546     1        1     0\n",
      "342  11665  41A08548  41A06546     1        1     0\n",
      "350  12265  55Z16490   52Y6490     1        1     1\n",
      "353  12311  51A91614  51A96141     1        1     0\n",
      "377  13621  48A05277  48A05177     1        1     0\n",
      "390  13797   61Z2959  61A22959     1        1     1\n",
      "394  13869   51A7210  51A72110     1        1     1\n",
      "459  17470       NaN  51A72110     1        1     0\n",
      "469  17653  51F25585  51F15585     1        1     0\n",
      "483  18843  56D65321  51F06532     1        1     0\n",
      "484  18976       NaN  51A85325     1        1     0\n",
      "485  18979       NaN  51A85325     1        1     0\n"
     ]
    }
   ],
   "source": [
    "# Đọc file CSV vào DataFrame\n",
    "merged_df = pd.read_csv('Evaluate.csv')\n",
    "\n",
    "zero_Predict_ratio = (merged_df['Predict'] == 0).sum() / len(merged_df) * 100\n",
    "miss_Predict_ratio = (merged_df['Miss'] == 1).sum()/ len(merged_df) * 100\n",
    "right_Predict_ratio = 100 - ((merged_df['Diff'] == 1).sum()) / len(merged_df) * 100\n",
    "wrong_Predict = (merged_df['Diff'] == 1).sum()- (merged_df['Predict'] == 0 - (merged_df['Miss'] == 1).sum()).sum()\n",
    "wrong_Predict_ratio = wrong_Predict / len(merged_df) * 100\n",
    "\n",
    "print(\"Số ảnh kiểm thử: \", len(merged_df))\n",
    "print(\"Tỉ lệ không thể nhận diện biển số: {:.2f}%\".format(zero_Predict_ratio))\n",
    "print(\"Tỉ lệ đọc sai biển số: {:.2f}%\".format(wrong_Predict_ratio- miss_Predict_ratio))\n",
    "print(\"Tỉ lệ đọc thiếu chữ số: {:.2f}%\".format(miss_Predict_ratio))\n",
    "print(\"Tỉ lệ biển số đọc đúng: {:.2f}%\".format(right_Predict_ratio))\n",
    "\n",
    "mask = (merged_df['Diff'] == 1)\n",
    "df_filtered = merged_df.loc[mask]\n",
    "print(df_filtered)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3873cd2ef03e533f5459bd62292e7d26e379cc846364ad23d69555a2118848c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
