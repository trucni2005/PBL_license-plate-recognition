{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test đọc video nhận diện biển số trên video"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test đọc biển số cho từng khung hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dangt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using cache found in C:\\Users\\dangt/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-3-20 Python-3.10.0 torch-1.13.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'frame_22.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18924/3307078159.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ultralytics/yolov5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'custom'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weights/last.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'frame_22.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\utils\\general.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(path, flags)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1123\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'frame_22.jpg'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "import torch\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='weights/last.pt')\n",
    "\n",
    "image = cv2.imread('frame_22.jpg')\n",
    "\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow(\"Image\", image)\n",
    "results = model(image)\n",
    "results.show()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test cắt tọa độ biển số xe trong khung hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='weights/last.pt')\n",
    "\n",
    "image = cv2.imread('frame_22.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "results = model(image)\n",
    "\n",
    "for i, det in enumerate(results.xyxy[0]):\n",
    "    # Lấy tọa độ bbox của vật thể thứ i\n",
    "    bbox = det[0:4].cpu().numpy()\n",
    "\n",
    "    # In ra tọa độ bbox của vật thể thứ i\n",
    "    print(f'Bbox {i}: {bbox}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hàm get ảnh kí tự ra folder char để phân loại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getchar(image, k, model):\n",
    "    print(k)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = model(image)\n",
    "\n",
    "    for i, det in enumerate(results.xyxy[0]):\n",
    "        # Lấy tọa độ bbox của vật thể thứ i\n",
    "        bbox = det[0:4].cpu().numpy()\n",
    "\n",
    "        # Cắt lấy vùng ảnh nằm trong bbox\n",
    "        cropped_image = image[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
    "        cropped_image = cv2.resize(cropped_image, (256, 100))\n",
    "        # cv2.imshow(f\"Cropped image {i}\", cropped_image)\n",
    "        # Chuyển ảnh sang đen trắng\n",
    "        gray = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        edges = cv2.Canny(blurred, threshold1=30, threshold2=100)\n",
    "        edges = cv2.bitwise_not(edges)\n",
    "        # cv2.imshow(f\"Cropped image {i}\", edges)\n",
    "        \n",
    "        # Sử dụng hàm connectedComponents để tìm các vùng kết nối trên ảnh nhị phân\n",
    "        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "        num_labels, labels = cv2.connectedComponents(binary)\n",
    "\n",
    "        # Hiển thị số lượng các labels tìm được\n",
    "        # print(f\"Number of labels: {num_labels-1}\")\n",
    "\n",
    "        d = 0\n",
    "        # Sử dụng hàm connectedComponentsWithStats để tính toán diện tích của các vùng kết nối\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary)\n",
    "        for i in range(num_labels):\n",
    "            area = stats[i, cv2.CC_STAT_AREA]\n",
    "            if area < 100 or area > 1500:\n",
    "                labels[labels == i] = 0\n",
    "            else: \n",
    "                d = d+1\n",
    "                # làm gì chưa biết? :D\n",
    "                # hmm\n",
    "        \n",
    "            # Lặp qua các nhãn\n",
    "        if (d > 5 and d < 10):\n",
    "            for i in range(1, num_labels):\n",
    "            # Lấy thông tin của nhãn hiện tại\n",
    "                x, y, w, h, area = stats[i]\n",
    "\n",
    "            # Nếu diện tích của nhãn nằm trong khoảng từ 100 đến 1500\n",
    "                if 100 < area < 1500:\n",
    "                # Cắt ảnh của nhãn hiện tại từ ảnh gốc\n",
    "                    digit_img = binary[y:y+h, x:x+w]\n",
    "\n",
    "                # Lưu ảnh ký tự\n",
    "                    print(k)\n",
    "                    cv2.imwrite(f\"./char/char_{k}.png\", digit_img)\n",
    "                    k = k+1\n",
    "            # print(labels)\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\dangt/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-3-20 Python-3.10.0 torch-1.13.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77540\n",
      "77540\n",
      "77541\n",
      "77542\n",
      "77543\n",
      "77544\n",
      "77545\n",
      "77546\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "import os\n",
    "\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='weights/last.pt')\n",
    "img = cv2.imread(\"kiemthu/17309.jpg\")\n",
    "getchar(img, 77640, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Đường dẫn đến thư mục chứa ảnh\n",
    "folder_path = './char'\n",
    "\n",
    "# Lặp qua từng file trong thư mục\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Đường dẫn đầy đủ đến file\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "    # Kiểm tra nếu file đó là ảnh\n",
    "    if os.path.isfile(file_path) and file_path.endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "        # Mở ảnh bằng Pillow\n",
    "        img = Image.open(file_path)\n",
    "\n",
    "        # Resize ảnh về kích thước rộng 25, cao 60\n",
    "        img = img.resize((25, 60))\n",
    "\n",
    "        # Lưu ảnh lại\n",
    "        img.save(file_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get kí tự cho toàn folder dataChar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "import os\n",
    "\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='weights/last.pt')\n",
    "# Đường dẫn đến tập char\n",
    "path = \"dataChar/\"\n",
    "\n",
    "i = 0\n",
    "# Duyệt qua các ảnh trong thư mục\n",
    "for filename in os.listdir(path):\n",
    "    img = cv2.imread(path + filename)\n",
    "    getchar(img, i, model)\n",
    "    i = i + 8\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dangt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using cache found in C:\\Users\\dangt/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-3-20 Python-3.10.0 torch-1.13.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "import os\n",
    "\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='weights/last.pt')\n",
    "\n",
    "image = cv2.imread('frame_22.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "results = model(image)\n",
    "\n",
    "for i, det in enumerate(results.xyxy[0]):\n",
    "    # Lấy tọa độ bbox của vật thể thứ i\n",
    "    bbox = det[0:4].cpu().numpy()\n",
    "\n",
    "    # Cắt lấy vùng ảnh nằm trong bbox\n",
    "    cropped_image = image[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
    "    cropped_image = cv2.resize(cropped_image, (256, 100))\n",
    "    # cv2.imshow(f\"Cropped image {i}\", cropped_image)\n",
    "    # Chuyển ảnh sang đen trắng\n",
    "    gray = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blurred, threshold1=30, threshold2=100)\n",
    "    edges = cv2.bitwise_not(edges)\n",
    "    # cv2.imshow(f\"Cropped image {i}\", edges)\n",
    "    \n",
    "    # Sử dụng hàm connectedComponents để tìm các vùng kết nối trên ảnh nhị phân\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    num_labels, labels = cv2.connectedComponents(binary)\n",
    "\n",
    "    # Hiển thị số lượng các labels tìm được\n",
    "    # print(f\"Number of labels: {num_labels-1}\")\n",
    "\n",
    "    d = 0\n",
    "    # Sử dụng hàm connectedComponentsWithStats để tính toán diện tích của các vùng kết nối\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary)\n",
    "    for i in range(num_labels):\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        if area < 100 or area > 1500:\n",
    "            labels[labels == i] = 0\n",
    "        else: \n",
    "            d = d+1\n",
    "            # làm gì chưa biết? :D\n",
    "            # hmm\n",
    "    \n",
    "        # Lặp qua các nhãn\n",
    "    if (d > 5 and d < 10):\n",
    "        for i in range(1, num_labels):\n",
    "        # Lấy thông tin của nhãn hiện tại\n",
    "            x, y, w, h, area = stats[i]\n",
    "\n",
    "        # Nếu diện tích của nhãn nằm trong khoảng từ 100 đến 1500\n",
    "            if 100 < area < 1500:\n",
    "            # Cắt ảnh của nhãn hiện tại từ ảnh gốc\n",
    "                digit_img = binary[y:y+h, x:x+w]\n",
    "\n",
    "            # Thực hiện xử lý ảnh cho phù hợp với mô hình nhận dạng ký tự\n",
    "            # ...\n",
    "\n",
    "            # Lưu ảnh ký tự\n",
    "                cv2.imwrite(f\"digit2_{i}.png\", digit_img)\n",
    "        # print(labels)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    label_hue = np.uint8(179 * labels / np.max(labels))\n",
    "\n",
    "    blank_ch = 255 * np.ones_like(label_hue)\n",
    "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "    labeled_img[label_hue == 0] = 0\n",
    "    \n",
    "\n",
    "\n",
    "    # Hiển thị ảnh với các vùng kết nối được tô màu\n",
    "    cv2.imshow(\"Connected components\", labeled_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    gray = cv2.cvtColor(labeled_img, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blurred, threshold1=30, threshold2=100)\n",
    "    edges = cv2.bitwise_not(edges)\n",
    "    cv2.imshow(\"Sau khi loai nhieu: \", edges)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    # Sử dụng hàm connectedComponents để tìm các vùng kết nối trên ảnh nhị phân\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    num_labels, labels = cv2.connectedComponents(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(folder_path, file):\n",
    "    print(folder_path)\n",
    "    binaries = []\n",
    "\n",
    "    # Lặp qua tất cả các tệp tin trong thư mục\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Nếu tệp tin có đuôi là '.png'\n",
    "        if filename.endswith('.png'):\n",
    "            # Đọc tệp tin ảnh bằng OpenCV\n",
    "            img = cv2.imread(os.path.join(folder_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "            ret, binary = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "            binaries.append(binary)\n",
    "        \n",
    "\n",
    "    # tính toán số lượng pixel màu đen và màu trắng cho từng pixel trong các ma trận\n",
    "    black_pixels = np.zeros_like(binaries[0])\n",
    "    white_pixels = np.zeros_like(binaries[0])\n",
    "    for binary in binaries:\n",
    "        black_pixels += binary == 0\n",
    "        white_pixels += binary == 255\n",
    "\n",
    "    # so sánh số lượng pixel màu đen và màu trắng để quyết định màu sắc cuối cùng của pixel trong ma trận đặc trưng\n",
    "    feature = np.zeros_like(binaries[0], dtype=np.uint8)\n",
    "    for i in range(feature.shape[0]):\n",
    "        for j in range(feature.shape[1]):\n",
    "            if black_pixels[i][j] > white_pixels[i][j]:\n",
    "                feature[i][j] = 0\n",
    "            else:\n",
    "                feature[i][j] = 255\n",
    "\n",
    "    # xuất ra ma trận nhị phân đặc trưng\n",
    "    np.savetxt('featured/featured'+file+'.txt', feature, fmt='%d')\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char/0\n",
      "char/1\n",
      "char/2\n",
      "char/3\n",
      "char/4\n",
      "char/5\n",
      "char/6\n",
      "char/7\n",
      "char/8\n",
      "char/9\n",
      "char/A\n",
      "char/B\n",
      "char/C\n",
      "char/D\n",
      "char/F\n",
      "char/G\n",
      "char/L\n",
      "char/N\n",
      "char/V\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "features = []\n",
    "folder_path = \"char/\"\n",
    "files = os.listdir(folder_path)\n",
    "for file in files:\n",
    "    if os.path.isdir(os.path.join(folder_path, file)):\n",
    "        folder_path_ii = os.path.join(folder_path, file)\n",
    "        features.append(feature(folder_path_ii, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(binary):\n",
    "    n = 0\n",
    "    max = 0\n",
    "    i = 0\n",
    "    # So sánh với feature\n",
    "    for file in files:\n",
    "        matching_pixels = np.sum(binary == features[i])\n",
    "        total_pixels = binary.shape[0] * binary.shape[1]\n",
    "        matching_percentage = matching_pixels / total_pixels * 100\n",
    "        if (matching_percentage>max): \n",
    "            n = i\n",
    "            max = matching_percentage\n",
    "        i = i + 1\n",
    "    return n\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPlate(image, model):\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = model(image)\n",
    "\n",
    "    for i, det in enumerate(results.xyxy[0]):\n",
    "        # Lấy tọa độ bbox của vật thể thứ i\n",
    "        bbox = det[0:4].cpu().numpy()\n",
    "\n",
    "        # Cắt lấy vùng ảnh nằm trong bbox\n",
    "        cropped_image = image[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
    "        cropped_image = cv2.resize(cropped_image, (256, 100))\n",
    "        # cv2.imshow(f\"Cropped image {i}\", cropped_image)\n",
    "        # Chuyển ảnh sang đen trắng\n",
    "        gray = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        edges = cv2.Canny(blurred, threshold1=30, threshold2=100)\n",
    "        edges = cv2.bitwise_not(edges)\n",
    "        # cv2.imshow(f\"Cropped image {i}\", edges)\n",
    "        \n",
    "        # Sử dụng hàm connectedComponents để tìm các vùng kết nối trên ảnh nhị phân\n",
    "        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "        num_labels, labels = cv2.connectedComponents(binary)\n",
    "\n",
    "        # Hiển thị số lượng các labels tìm được\n",
    "        # print(f\"Number of labels: {num_labels-1}\")\n",
    "\n",
    "        d = 0\n",
    "        # Sử dụng hàm connectedComponentsWithStats để tính toán diện tích của các vùng kết nối\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary)\n",
    "        for i in range(num_labels):\n",
    "            area = stats[i, cv2.CC_STAT_AREA]\n",
    "            if area < 100 or area > 1500:\n",
    "                labels[labels == i] = 0\n",
    "            else: \n",
    "                d = d+1\n",
    "                # làm gì chưa biết? :D\n",
    "                # hmm\n",
    "        \n",
    "        x_centroids = centroids[:, 0] # Lấy tất cả các hàng, cột đầu tiên (tương ứng với tọa độ x)\n",
    "        \n",
    "        predicted = \"\"\n",
    "        xx = []\n",
    "        # Lặp qua các nhãn\n",
    "        if (d > 5 and d < 11):\n",
    "            for i in range(1, num_labels):\n",
    "            # Lấy thông tin của nhãn hiện tại\n",
    "                x, y, w, h, area = stats[i]\n",
    "\n",
    "            # Nếu diện tích của nhãn nằm trong khoảng từ 100 đến 1500\n",
    "                if 100 < area < 1500:\n",
    "                # Cắt ảnh của nhãn hiện tại từ ảnh gốc\n",
    "                    digit_img = binary[y:y+h, x:x+w]\n",
    "                    digit_img = cv2.resize(digit_img, (25,60))\n",
    "                    xx.append((x_centroids[i], predict(digit_img)))\n",
    "                    # np.savetxt('featuretest'+str(i)+'.txt', digit_img, fmt='%d')\n",
    "                    # if (predict(digit_img) <= 9):\n",
    "                    #     predicted = predicted + str(predict(digit_img))\n",
    "                    # if (predict(digit_img) == 10):\n",
    "                    #     predicted = predicted + \"A\"\n",
    "                    # if (predict(digit_img) == 11):\n",
    "                    #     predicted = predicted + \"F\"\n",
    "                    # if (predict(digit_img) == 12):\n",
    "                    #     predicted = predicted + \"G\"\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        sorted_list = sorted(xx, key=lambda x: x[0])\n",
    "\n",
    "        predicted = \"\"\n",
    "\n",
    "        for x, value in sorted_list:\n",
    "            if (value == 10):\n",
    "                predicted += \"A\"\n",
    "            elif (value == 11):\n",
    "                predicted += \"B\"\n",
    "            elif (value == 12):\n",
    "                predicted += \"C\"\n",
    "            elif (value == 13):\n",
    "                predicted += \"D\"\n",
    "            elif (value == 14):\n",
    "                predicted += \"F\"\n",
    "            elif (value == 15):\n",
    "                predicted += \"G\"\n",
    "            elif (value == 16):\n",
    "                predicted += \"L\"\n",
    "            elif (value == 17):\n",
    "                predicted += \"N\"\n",
    "            elif (value == 18):\n",
    "                predicted += \"V\"\n",
    "            else:\n",
    "                predicted += str(value)\n",
    "        # print(\"Biển số xe dự đoán được là: \"+ predicted)\n",
    "\n",
    "        # print(\"Nhãn dự đoán: \", predicted)\n",
    "        # h, w = image.shape[:2]\n",
    "        # label_hue = np.uint8(179 * labels / np.max(labels))\n",
    "\n",
    "        # blank_ch = 255 * np.ones_like(label_hue)\n",
    "        # labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "        # labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "        # labeled_img[label_hue == 0] = 0\n",
    "        \n",
    "\n",
    "\n",
    "        # # Hiển thị ảnh với các vùng kết nối được tô màu\n",
    "        # cv2.imshow(\"Connected components\", labeled_img)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "        # gray = cv2.cvtColor(labeled_img, cv2.COLOR_BGR2GRAY)\n",
    "        # blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        # edges = cv2.Canny(blurred, threshold1=30, threshold2=100)\n",
    "        # edges = cv2.bitwise_not(edges)\n",
    "        # cv2.imshow(\"Sau khi loai nhieu: \", edges)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "        # # Sử dụng hàm connectedComponents để tìm các vùng kết nối trên ảnh nhị phân\n",
    "        # _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "        # num_labels, labels = cv2.connectedComponents(binary)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\dangt/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-3-20 Python-3.10.0 torch-1.13.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'outputofkt.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12400/2756080828.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Xuất ra file CSV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'outputofkt.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dangt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dangt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3718\u001b[0m         )\n\u001b[0;32m   3719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3720\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3721\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3722\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dangt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dangt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m         )\n\u001b[1;32m-> 1189\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dangt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \"\"\"\n\u001b[0;32m    240\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dangt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'outputofkt.csv'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='weights/best.pt')\n",
    "\n",
    "folder_path = \"kiemthu/\" # đường dẫn đến folder chứa ảnh\n",
    "\n",
    "predicted = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"): \n",
    "        # kiểm tra xem file có phải là ảnh jpg hoặc png không\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        img = cv2.imread(file_path) # đọc ảnh bằng OpenCV\n",
    "        # sử dụng ảnh tại đây\n",
    "        predicted.append((filename, readPlate(img, model)))\n",
    "\n",
    "# Tạo DataFrame từ mảng\n",
    "df = pd.DataFrame(predicted, columns=['Ảnh', 'Đọc biển số'])\n",
    "\n",
    "# Xuất ra file CSV\n",
    "df.to_csv('outputofkt.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dangt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using cache found in C:\\Users\\dangt/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-3-20 Python-3.10.0 torch-1.13.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.93834)\n",
      "1\n",
      "tensor(0.96015)\n",
      "1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'readPlate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2936/260565007.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.95\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mresult_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadPlate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_frame\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;31m# Vẽ chuỗi result_s lên khung hình results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'readPlate' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "import torch\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='weights/best.pt')\n",
    "\n",
    "# Tạo một đối tượng VideoCapture để đọc video\n",
    "cap = cv2.VideoCapture('test.MOV')\n",
    "\n",
    "# Lấy kích thước khung hình của video\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Tạo đối tượng VideoWriter để ghi video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('processed_video.mp4', fourcc, 30, (width, height))\n",
    "# Đọc từng khung hình của video, xử lý và ghi lại\n",
    "result_s = ''\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Xử lý khung hình ở đây\n",
    "    processed_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = model(processed_frame)\n",
    "    print(len(results.pred))\n",
    "    accuracy = float(results.pred[0][0][4].item())\n",
    "    if (accuracy >= 0.95):\n",
    "        result_s = readPlate(processed_frame,model)\n",
    "    # Vẽ chuỗi result_s lên khung hình results\n",
    "    cv2.putText(results.render()[0], result_s, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    # Ghi khung hình đã xử lý vào đối tượng VideoWriter\n",
    "    out.write(cv2.cvtColor(results.render()[0], cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # # Hiển thị khung hình đã xử lý\n",
    "    cv2.imshow('Processed Frame', cv2.cvtColor(results.render()[0], cv2.COLOR_RGB2BGR))\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Giải phóng các tài nguyên và đóng các cửa sổ hiển thị\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
